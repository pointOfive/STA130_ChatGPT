{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ae681ef",
   "metadata": {},
   "source": [
    "## STA130 Homework 03 \n",
    "\n",
    "Please see the course [wiki-textbook](https://github.com/pointOfive/STA130_ChatGPT/wiki) for the list of topics covered in this homework assignment, and a list of topics that might appear during ChatBot conversations which are \"out of scope\" for the purposes of this homework assignment (and hence can be safely ignored if encountered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf135c01",
   "metadata": {},
   "source": [
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Introduction</u></summary>\n",
    "\n",
    "### Introduction\n",
    "\n",
    "A reasonable characterization of STA130 Homework is that it simply defines a weekly reading comprehension assignment. \n",
    "Indeed, STA130 Homework essentially boils down to completing various understanding confirmation exercises oriented around coding and writing tasks.\n",
    "However, rather than reading a textbook, STA130 Homework is based on ChatBots so students can interactively follow up to clarify questions or confusion that they may still have regarding learning objective assignments.\n",
    "\n",
    "> Communication is a fundamental skill underlying statistics and data science, so STA130 Homework based on ChatBots helps practice effective two-way communication as part of a \"realistic\" dialogue activity supporting underlying conceptual understanding building. \n",
    "\n",
    "It will likely become increasingly tempting to rely on ChatBots to \"do the work for you\". But when you find yourself frustrated with a ChatBots inability to give you the results you're looking for, this is a \"hint\" that you've become overreliant on the ChatBots. Your objective should not be to have ChatBots \"do the work for you\", but to use ChatBots to help you build your understanding so you can efficiently leverage ChatBots (and other resources) to help you work more efficiently.<br><br>\n",
    "\n",
    "</details>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Instructions</u></summary>\n",
    "\n",
    "### Instructions\n",
    "    \n",
    "1. Code and write all your answers (for both the \"Prelecture\" and \"Postlecture\" HW) in a python notebook (in code and markdown cells) \n",
    "    \n",
    "    > It is *suggested but not mandatory* that you complete the \"Prelecture\" HW prior to the Monday LEC since (a) all HW is due at the same time; but, (b) completing some of the HW early will mean better readiness for LEC and less of a \"procrastentation cruch\" towards the end of the week...\n",
    "    \n",
    "2. Paste summaries of your ChatBot sessions (including link(s) to chat log histories if you're using ChatGPT) within your notebook\n",
    "    \n",
    "    > Create summaries of your ChatBot sessions by using concluding prompts such as \"Please provide a summary of our exchanges here so I can submit them as a record of our interactions as part of a homework assignment\" or, \"Please provide me with the final working verson of the code that we created together\"\n",
    "    \n",
    "3. Save your python jupyter notebook in your own account and \"repo\" on [github.com](github.com) and submit a link to that notebook though Quercus for assignment marking<br><br>\n",
    "\n",
    "</details>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Prompt Engineering?</u></summary>\n",
    "\n",
    "### Prompt Engineering? \n",
    "\n",
    "    \n",
    "The questions (as copy-pasted prompts) are designed to initialize appropriate ChatBot conversations which can be explored in the manner of an interactive and dynamic textbook; but, it is nonetheless **strongly recommendated** that your rephrase the questions in a way that you find natural to ensure a clear understanding of the question. Given sensible prompts the represent a question well, the two primary challenges observed to arise from ChatBots are \n",
    "\n",
    "1. conversations going beyond the intended scope of the material addressed by the question; and, \n",
    "2. unrecoverable confusion as a result of sequential layers logial inquiry that cannot be resolved. \n",
    "\n",
    "In the case of the former (1), adding constraints specifying the limits of considerations of interest tends to be helpful; whereas, the latter (2) is often the result of initial prompting that leads to poor developments in navigating the material, which are likely just best resolve by a \"hard reset\" with a new initial approach to prompting.  Indeed, this is exactly the behavior [hardcoded into copilot](https://answers.microsoft.com/en-us/bing/forum/all/is-this-even-normal/0b6dcab3-7d6c-4373-8efe-d74158af3c00)...\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5c2517",
   "metadata": {},
   "source": [
    "### Marking Rubric (which may award partial credit) \n",
    "\n",
    "- [0.1 points]: All relevant ChatBot summaries [including link(s) to chat log histories if you're using ChatGPT] are reported within the notebook\n",
    "- [0.2 points]: Assignment completion confirmed by submission and ChatBot interaction summaries for \"2\"\n",
    "- [0.2 points]: Evaluation of written communication for \"3\"\n",
    "- [0.1 points]: Correct answers for \"4\"\n",
    "- [0.3 points]: Assignment completion confirmed by ChatBot interaction summaries for \"5\"\n",
    "- [0.1 points]: Evidence of activity for \"6\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3728b0b6",
   "metadata": {},
   "source": [
    "### \"Prelecture\" HW [*completion prior to next LEC is suggested but not mandatory*]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de55c16a",
   "metadata": {},
   "source": [
    "#### 1. Use [`fig.add_[h/v]line()`](https://plotly.com/python/horizontal-vertical-shapes/) and [`fig.add_[h/v]rect()`](https://plotly.com/python/line-charts/)to mark, respspectively, location (mean and median) and scale (range, interquartile range, and a range defined by two standard deviations away from the mean in both directions) of *flipper_length_mm* for each *species* onto *plotly* histograms of *flipper_length_mm* for each *species* in the penguins dataset<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _There are several considerations in this problem..._ \n",
    ">\n",
    ">    > _The histograms can be on the same figure, on separate figures, or separated into different panels in the same figure_ \n",
    ">\n",
    ">    > _The elements within a figure should be well annotated, probobably using a so-called legend to help make sure annotations don't overlap each other and are clear and readible_\n",
    ">\n",
    "> _There are several ways to approach this problem..._\n",
    ">\n",
    ">    > _You will likely be very pleased when you run the code returned to you as the result of pasting ths question in as a prompt into a ChatBot session; but, you will also likely need to interact with the ChatBot to ask for adjustments to the code which give a final satisfactory figure (and this is the recommended approach to get the experience this problem intends you to have)_\n",
    ">\n",
    ">    > _You could alternatively figure out how to code this plot up for yourself by looking at the provided documentation links and perhaps using some additional google searchers or ChatBot queries to help out with specific issues or examples; and, if you end up interested in figuring out a little more how the code works that's great and definitely feel free to go ahead and do so, but at this stage the point of this problem is to understand the general ideas of figures themselves as opposed to being an expert about the code that generated them_\n",
    "    \n",
    "</details>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d8cf32",
   "metadata": {},
   "source": [
    "#### 2. Transition your ChatBot session from the previous problem to repeat the previous problem, but this time using [*seaborn* **kernel density estimation** (KDE) plots](https://seaborn.pydata.org/generated/seaborn.kdeplot.html) to produce the desired figures organized in row of three plots<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "    \n",
    "> _The `seaborn` library extends `matplotlib` so [ax.axhspan(...)](https://matplotlib.org/stable/gallery/subplots_axes_and_figures/axhspan_demo.html#sphx-glr-gallery-subplots-axes-and-figures-axhspan-demo-py) or [ax.fill_between(...)](\n",
    "https://matplotlib.org/stable/gallery/lines_bars_and_markers/span_regions.html) from `matplotlib` could be combined with the `seaborn` KDE plot... this might be something to share with your ChatBot [if it tries to keep using `plotly` or a KDE function rather than a KDE plotting functionality...](../CHATLOG/wk3/GPT/SLS/00001_gpt3p5_plotlyseaborn_plotting.md)_\n",
    "> \n",
    "> _The technical details of the following are beyond the scope of STA130; but, if you were interested, you could very briefly examine the [`seaborn` themes](https://seaborn.pydata.org/tutorial/aesthetics.html) based on `sns.set_style()` and `sns.set_theme()` and [colors](https://seaborn.pydata.org/tutorial/color_palettes.html) based on the `palette` parameter, e.g.,_\n",
    "> \n",
    "```python\n",
    "sns.set_style(\"whitegrid\") # sns.set_style(\"dark\")\n",
    "# `sns.set_palette()` exists but functions often access and set that directly\n",
    "sns.boxplot(..., hue='column', palette=\"colorblind\") \n",
    "```    \n",
    "> \n",
    "> _and then attempt to interact with the ChatBot to change the coloring of the figure to something that you like and looks more clear to you..._\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f2f38b",
   "metadata": {},
   "source": [
    "#### 3. Discuss the basic difference between **histograms** and **kernel density estimators** your ChatBot and describe your preference for one or the other and your rationale for this preference<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "    \n",
    "> _Don't forget to ask for summaries of your ChatBot session(s) and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatGPT)_\n",
    ">    \n",
    ">    > _The details of the [\"kernel\"](https://en.wikipedia.org/wiki/Kernel_density_estimation) and how it works in [kernel density estimation](https://plotly.com/python/violin/#split-violin-plot) are beyond the scope of STA130; but, there is typically a so-called \"bandwidth\" parameter that \"controls the width of the kernel\" which is analgous to the \"number of bins parameter\" of a histogram (e.g., `nbins` in [*plotly*](https://www.google.com/search?client=safari&rls=en&q=plotly+nbins&ie=UTF-8&oe=UTF-8)); so, the choice of the number of histogram bins is analgous to specifying KDE bandwidth (e.g., `bw_adjust` in [*seaborn*](https://stackoverflow.com/questions/37932283/confusion-with-bandwidth-on-seaborns-kdeplot))_  \n",
    "    </details>   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8cc949",
   "metadata": {},
   "source": [
    "#### 4. Run the code below and look at the resulting figure of distrubutions and then answer the following questions<br><br>\n",
    "\n",
    "1. Which datasets have similar means and similar variances<br><br>\n",
    "2. Which datasets have similar means but quite different variances<br><br>\n",
    "3. Which datasets have similar variances but quite different means<br><br>\n",
    "4. Which datasets have quite different means and quite different variances<br><br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "    \n",
    "> _Can you answer these questions immediately? If not, first review what the basic ideas of means and variances (and standard deviations) are. Their mathematical definitions are give below, but these are just the definitions and you may or may not yet find them helpful for understanding the intuition of these concepts..._\n",
    ">\n",
    ">    > _mean $\\displaystyle \\bar x = \\frac{1}{n}\\sum_{i=1}^n x_i$_ \n",
    ">    >\n",
    ">    > _variance $\\displaystyle s^2 = \\frac{1}{n-1}\\sum_{i=1}^n (x_i-\\bar x)^2$_\n",
    ">    >\n",
    ">    > _standard deviation $\\displaystyle s = \\sqrt{s^2}$_\n",
    ">\n",
    "> _It's also possible that you or a ChatBot could answer these questions by looking at the code that produced the data you're considering. But if you're trying to check and understand things using code, you should instead consider just determining this directly based on calculating the statistics that answer the questions themselves..._\n",
    ">    > _`np.mean(df.col)` or `df.col.mean()`_\n",
    ">    >\n",
    ">    > `_np.std(df.col, dof=1)` / `np.var(df.col, dof=1)` or `df.col.std(dof=1)` / `df.col.var(dof=1)`_\n",
    ">\n",
    "> _If you are resorting to calculating the statistics that answer the questions, try to understand the answers after you have them... just getting the \"right\" answers kind of defeats the point of this exercise..._\n",
    ">\n",
    ">    > _The difference between trying to answer this question using the code that produced the data versus calculating the statistics from the data comes down to the difference between *parameters* and *statistics*, but this will be discussed in the lecture... in the meantime, howevever, if you're curious about this... you could consider prompting a ChatBot to explain the difference between *parameters* and *statistics*..._\n",
    ">    >\n",
    ">    > _... this would naturally lead to some discussion of the relationship between *populations* and *samples*, and from there you would need to go a little further to  start working to understand the relationship between *statistics* and *parameters* and how they connect to *populations* and *samples* (and hence each other)..._    \n",
    "    \n",
    "</details>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c149e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "\n",
    "n=1500\n",
    "data1 = stats.uniform.rvs(0, 10, size=n)\n",
    "data2 = stats.norm.rvs(5, 1.5, size=n)\n",
    "data3 = np.r_[stats.norm.rvs(2, 0.25, size=int(n/2)), stats.norm.rvs(8, 0.5, size=int(n/2))]\n",
    "data4 = stats.norm.rvs(6, 0.5, size=n)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=4)\n",
    "\n",
    "fig.add_trace(go.Histogram(x=data1, name='A', nbinsx=30, marker=dict(line=dict(color='black', width=1))), row=1, col=1)\n",
    "fig.add_trace(go.Histogram(x=data2, name='B', nbinsx=15, marker=dict(line=dict(color='black', width=1))), row=1, col=2)\n",
    "fig.add_trace(go.Histogram(x=data3, name='C', nbinsx=45, marker=dict(line=dict(color='black', width=1))), row=1, col=3)\n",
    "fig.add_trace(go.Histogram(x=data4, name='D', nbinsx=15, marker=dict(line=dict(color='black', width=1))), row=1, col=4)\n",
    "\n",
    "fig.update_layout(height=300, width=750, title_text=\"Row of Histograms\")\n",
    "fig.update_xaxes(title_text=\"A\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"B\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"C\", row=1, col=3)\n",
    "fig.update_xaxes(title_text=\"D\", row=1, col=4)\n",
    "fig.update_xaxes(range=[-0.5, 10.5])\n",
    "\n",
    "for trace in fig.data:\n",
    "    trace.xbins = dict(start=0, end=10)\n",
    "    \n",
    "# This code was produced by just making requests to Microsoft Copilot (../CHATLOG/wk3/COP/SLS/0001_concise_makeAplotV1.md)\n",
    "\n",
    "fig.show() # USE `fig.show(renderer=\"png\")` FOR ALL GitHub and MarkUs SUBMISSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4131b13",
   "metadata": {},
   "source": [
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Continue now...?</u></summary>\n",
    "\n",
    "### Prelecture VS Postlecture HW\n",
    "\n",
    "Feel free to work on the \"Postlecture\" HW below if you're making good progress and want to continue: the next questions will just continue working on data visualization related topics, so, it's just a choice whether or not you want to work a head a little bit... \n",
    "\n",
    "> The previous suggestions regarding *parameters* versus *statistics* would be a very good thing to look at carefully in preparation for the upcoming lecture...\n",
    "    \n",
    "*The benefits of continue would are that (a) it might be fun to try to tackle the challenge of working through some problems without additional preparation or guidance; and (b) this is a very valable skill to be comfortable with; and (c) it will let you build experience interacting with ChatBots (and beginning to understand their strengths and limitations in this regard)... it's good to have sense of when using a ChatBot is the best way to figure something out, or if another approach (such as course provided resources or a plain old websearch for the right resourse) would be more effective*\n",
    "    \n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b46599",
   "metadata": {},
   "source": [
    "### \"Postlecture\" HW [*submission along with \"Prelecture\" HW is due prior to next TUT*]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed730173",
   "metadata": {},
   "source": [
    "#### 5. Start a new ChatBot session to explore the general relationship between the *mean* and *median* and \"right\" and \"left\" skewness (and why this is); what the following code does and how it works; and then explain (in your own words) the relationship between the *mean* and *median* and \"right\" and \"left\" skewness and what causes this, using the code to demonstrate your explanation through a sequence of notebook cells.<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "    \n",
    "> _Don't forget to ask for summaries of your ChatBot session(s) and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatGPT)... you could start this session perhaps something like [this](../CHATLOG/wk3/GPT/SLS/00003_GPT3p5_meanVmedian.md)?_\n",
    "\n",
    "</details> \n",
    "\n",
    "```python\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "sample1 = stats.gamma(a=2,scale=2).rvs(size=1000)\n",
    "fig1 = px.histogram(pd.DataFrame({'data': sample1}), x=\"data\")\n",
    "# USE `fig1.show(renderer=\"png\")` FOR ALL GitHub and MarkUs SUBMISSIONS\n",
    "\n",
    "sample1.mean()\n",
    "np.quantile(sample1, [0.5]) # median\n",
    " \n",
    "sample2 = -stats.gamma(a=2,scale=2).rvs(size=1000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3af6ca",
   "metadata": {},
   "source": [
    "#### 6. Go find an interesting dataset and use summary statistics and visualizations to understand and demonstate some interesting aspects of the data<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u><em></summary>\n",
    "    \n",
    "> _Your approach should likely follow what was suggested for the Communication Activity from TUT_\n",
    ">\n",
    "> _In the next TUT you will be put in groups and determine which group members dataset analysis will be presented by the group_\n",
    ">    > _A good place to browse datasets is [TidyTuesday](https://github.com/rfordatascience/tidytuesday/blob/master/README.md) as working with ChatBots to find unconventional and entertaining datasets is not particularly productive and only seems to end up with the datasets seen here and other (more interesting?) suggestions like [iris](https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv), [superheros](https://raw.githubusercontent.com/steview-d/superhero-dashboard/master/static/data/superheroData.csv), [hauntings](https://raw.githubusercontent.com/andreamoleri/Hauntings/main/hauntings.csv), [bigfoot](https://raw.githubusercontent.com/hannahramirez/BigfootVsUfos/main/bigfoot_mod.csv), [ufos](https://raw.githubusercontent.com/hannahramirez/BigfootVsUfos/main/ufo_mod.csv), [sharks](https://raw.githubusercontent.com/IbaiGallego/DataCleaning_SharkAttack/main/data/jaws.csv), [legos](https://raw.githubusercontent.com/seankross/lego/master/data-tidy/legosets.csv), [bees](https://gist.githubusercontent.com/bootshine2/ba15d3cb38e2ed31129aeca403405a12/raw/10949901cd8a6a75aa46c86b804c42ff410f929e/Bee%2520Colony%2520Loss.csv), [housing](https://raw.githubusercontent.com/slavaspirin/Toronto-housing-price-prediction/master/houses_edited.csv), and [gapminder](https://raw.githubusercontent.com/kirenz/datasets/master/gapminder.csv)_\n",
    "    \n",
    "```python\n",
    "# Maybe something like this? Feel free to use this one \n",
    "# if it strikes your fancy after look around a bit\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/manuelamc14/fast-food-Nutritional-Database/main/Tables/nutrition.csv\")\n",
    "df # df.columns\n",
    "```\n",
    "    \n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d14d681",
   "metadata": {},
   "source": [
    "#### 7. Watch the classic Gapminder Video, then have a look at the*plotly* version and recreate the animation (perhaps after optionally exploring and changing the style, if you wish)<br>\n",
    "\n",
    "[Gapminder Video](https://www.youtube.com/watch?v=jbkSRLYSojo)\n",
    "\n",
    "[*plotly* version](https://plotly.com/python/animations/) \n",
    "\n",
    "[style](https://plotly.com/python/templates/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0637fb5c",
   "metadata": {},
   "source": [
    "#### 8. Provide a second version of the figure from the previous problem where you edit the *fig = px.scatter()* function from the Gapminder code so that *x* is \"percent change\", *y* is \"rank\", *size* is \"percent\", and *color*=\"sex\", *animation_frame* is \"year\", and *animation_group* and *hover_name* are \"name\". Then use *size_max=50*, *range_x=[-0.005,0.005])* and remove the *log_x=True* and *range_y* parameters\n",
    "\n",
    "```python\n",
    "bn = pd.read_csv('https://raw.githubusercontent.com/hadley/data-baby-names/master/baby-names.csv')\n",
    "bn['name'] = bn['name']+\" \"+bn['sex'] # make identical boy and girl names distinct\n",
    "bn['rank'] = bn.groupby('year')['percent'].rank(ascending=False)\n",
    "bn = bn.sort_values(['name','year'])\n",
    "# the next three lines create the increaes or decrease in name prevalence from the last year \n",
    "bn['percent change'] = bn['percent'].diff()\n",
    "new_name = [True]+list(bn.name[:-1].values!=bn.name[1:].values)\n",
    "bn.loc[new_name,'percentage change'] = bn.loc[new_name,'percent'] \n",
    "bn = bn.sort_values('year')\n",
    "bn = bn[bn.percent>0.001] # restrict to \"common\" names\n",
    "fig = px.scatter(bn, x=\"\", y=\"\", animation_frame=\"\", animation_group=\"\",\n",
    "                  size=\"\", color=\"\", hover_name=\"\",size_max=50, range_x=[-0.005,0.005]) # range_y removed\n",
    "fig.update_yaxes(autorange='reversed') # this lets us put rank 1 on the top\n",
    "fig.show(renderer=\"png\") # USE `fig.show(renderer=\"png\")` FOR ALL GitHub and MarkUs SUBMISSIONS\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c953507",
   "metadata": {},
   "source": [
    "#### 9. Have you reviewed the course wiki-textbook and interacted with a ChatBot (or, if that wasn't sufficient, real people in the course piazza discussion board or TA office hours) to help you understand all the material in the tutorial and lecture that you didn't quite follow when you first saw it?<br><br>\n",
    "    \n",
    "[wiki-textbook](https://github.com/pointOfive/STA130_ChatGPT/wiki)\n",
    "    \n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "    \n",
    "> _Just answering \"Yes\" or \"No\" or \"Somewhat\" or \"Mostly\" or whatever here is fine as this question isn't a part of the rubric; but, the midterm and final exams may ask questions that are based on the tutorial and lecture materials; and, your own skills will be limited by your familiarity with these materials (which will determine your ability to actually do actual things effectively with these skills... like the course project...)_\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aab1be",
   "metadata": {},
   "source": [
    "## Recommended Additional Useful Activities [Optional]\n",
    "\n",
    "The \"Ethical Profesionalism Considerations\" and \"Current Course Project Capability Level\" sections below **are not a part of the required homework assignment**; rather, they are regular weekly guides covering (a) relevant considerations regarding professional and ethical conduct, and (b) the analysis steps for the STA130 course project that are feasible at the current stage of the course \n",
    "\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Ethical Professionalism Considerations</u></summary>\n",
    "\n",
    "## Ethical Professionalism Considerations\n",
    "\n",
    "|![](https://handsondataviz.org/images/14-detect/gdp-baseline-merged-annotated.png)|\n",
    "|-|\n",
    "| |\n",
    "\n",
    "Mark Twain's statment that, \"There are lies, damn lies, and statistics\", reflects a general skepticism towards statistical analysis that has been reinforced through through popular books such as [How to Lie with Statistics](https://en.wikipedia.org/wiki/How_to_Lie_with_Statistics). One place \"statistics\" can be used to decieve is through misuse of charts.  As discussed [here](https://handsondataviz.org/how-to-lie-with-charts.html) and many other places, a primary tactic that can be used to give a misleading impression using a chart is the manipulation of axes or the addition of additional dimensions which distort the meaning of size. **What are the problems with the following graphs?**\n",
    "\n",
    "|![](https://images.ctfassets.net/jicu8fwm4fvs/260tj0wxTFCAlbf4yTzSoy/2b002a49921831ab0dc05415616a1652/blog-misleading-gun-deaths-graph.jpeg)|![](https://photos1.blogger.com/blogger/5757/110/1600/macgraph.jpg)|\n",
    "|-|-|\n",
    "| | |\n",
    "\n",
    "</details>    \n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Current Course Project Capability Level</u></summary>\n",
    "\n",
    "## Current Course Project Capability Level\n",
    "\n",
    "#### Remember to abide by the [data use agreement](https://static1.squarespace.com/static/60283c2e174c122f8ebe0f39/t/6239c284d610f76fed5a2e69/1647952517436/Data+Use+Agreement+for+the+Canadian+Social+Connection+Survey.pdf) at all times\n",
    "\n",
    "At this point in the course you should be able to create a `for` loop to iterate through and provide **visualizations** of some of the interesting columns in the course project data\n",
    "\n",
    "> Create a `for` loop with a **conditional logic structure** that appropriately controls the kind of visualization that gets made for a given column of data based on its data type\n",
    ">\n",
    ">    > *Being able run your code with different subsets (of different types) of columns demonstrates the desirability of the programming design principle of \"polymorphism\" (which means \"many uses\") which states that code is best when it's \"resuable\" for different purposes... such as automatically providing the appropriate visualizations as interest in different variables dynamically changes...* \n",
    "</details>            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
