{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e1d847c",
   "metadata": {},
   "source": [
    "## Probability and Coding\n",
    "\n",
    "#### 1. Conditional Probability and Indepdenence\n",
    "\n",
    "1. **Probability** \n",
    "\n",
    "    $\\displaystyle \\Pr(A)\\quad \\textrm{or} \\quad\\Pr(X=x)$<br><br>\n",
    "    \n",
    "2. **Conditional Probability** \n",
    "\n",
    "    $\\displaystyle \\Pr(\\;A\\,|\\,B\\;)\\quad$ or $\\quad\\Pr(\\; Y=y\\,|\\,X=x\\;)$<br>\n",
    "    \n",
    "    ChatBots are something like the following specifications...\n",
    "\n",
    "    1. **Markov**: $\\Pr(\\; W_{i+1}=w_{i+1}\\,|\\,W_i=w_i\\;)$  \n",
    "    2. **Bigram**: $\\Pr(\\; W_{i+2}=w_{i+2}\\,|\\, W_{i+1}=w_{i+1}, W_i=w_i\\;)$  \n",
    "    3. **Trigram**: $\\Pr(\\; W_{i+3}=w_{i+3} \\,|\\, W_{i+2}=w_{i+2}, W_{i+1}=w_{i+1}, W_i=w_i\\;)$ \n",
    "    4. **Context**: $\\Pr(\\; W_{i+3}=w_{i+3} \\,|\\, W_{i+1}=w_{i+1}, W_i=w_i, C=c\\;)$<br><br>\n",
    "\n",
    "3. **Independence** \n",
    "\n",
    "    $\\displaystyle \\Pr(A)=\\Pr(\\;A\\,|\\,B\\;)\\quad$ or $\\quad\\Pr(Y=y) = \\Pr(\\; Y=y\\,|\\,X=x\\;)$\n",
    "\n",
    "#### 2. Multinomial distributions\n",
    "\n",
    "1. `from scipy import stats`\n",
    "2. `stats.multinomial(p=probability, n=categories).rvs(size=attempts)`\n",
    "3. `import numpy as np` and `np.array()`\n",
    "4. `np.random.seed(initialization)` and `np.random.choice(options, size=draws, replace=True, p=None)`\n",
    "\n",
    "#### 3. python string manipulation for a Markovian ChatBot\n",
    "\n",
    "- `avatar.dtypes` and `df.col.str.upper()`\n",
    "    - `.replace` and `import re` \"regular expressions\" (\"regexp\") are demonstrated but will not be tested \n",
    "- **Operator overloading** `+` and `.sum().split(' ')`\n",
    "- `for i in range(n)` and `for x in lst` and `for i,x in enumerate(lst)`\n",
    "- `list()` and `dict()`\n",
    "- `if`/`else`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9824444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.choice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b7d522",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-08-11/avatar.csv\"\n",
    "avatar = pd.read_csv(url) #avatar.isnull().sum() #avatar[avatar.isnull().sum(axis=1)>0]\n",
    "avatar[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15066249",
   "metadata": {},
   "outputs": [],
   "source": [
    "avatar.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe60d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "avatar.character.value_counts()#[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef477fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "avatar.chapter.value_counts()#[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ea9226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#words = (\"\\n\"+avatar.dropna().character.str.upper()+\": \"+avatar.dropna().character_words+\" \").sum().split(' ')\n",
    "#words = (\"\\n\"+avatar.dropna().character.str.upper()+\": \"+avatar.dropna().character_words+\" \").sum().split(' ')\n",
    "words = (\"\\n\"+avatar.character.str.upper().str.replace(' ','.')+\": \"+avatar.full_text+\" \").sum().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db29ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from collections import defaultdict\n",
    "word_used = dict()#defaultdict(int)\n",
    "next_word = dict()#defaultdict(lambda: defaultdict(int))\n",
    "for i,word in enumerate(words[:-1]):\n",
    "    \n",
    "    if word in word_used:\n",
    "        word_used[word] += 1\n",
    "    else: \n",
    "        word_used[word] = 1\n",
    "        next_word[word] = {}\n",
    "        \n",
    "    if words[i+1] in next_word[word]:\n",
    "        next_word[word][words[i+1]] += 1 \n",
    "    else:\n",
    "\n",
    "        next_word[word][words[i+1]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fe8831",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3df88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d63fc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_word = \"\\nKatara:\".upper()\n",
    "print(current_word, end=' ')\n",
    "for i in range(100):\n",
    "    probability_of_next_word = np.array(list(next_word[current_word].values()))/word_used[current_word]\n",
    "    randomly_chosen_next_word = stats.multinomial(p=probability_of_next_word, n=1).rvs(size=1)[0,:]\n",
    "    current_word = np.array(list(next_word[current_word].keys()))[1==randomly_chosen_next_word][0]\n",
    "    print(current_word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b642c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "avatar.full_text = avatar.full_text.apply(lambda string: re.sub(r'\\[.*?\\]', lambda match: match.group(0).replace(' ', '_ '), string))\n",
    "avatar.loc[avatar.character=='Scene Description','full_text'] = avatar.full_text[avatar.character=='Scene Description'].str.replace(' ', '- ')\n",
    "words = (\"\\n\"+avatar.character.str.upper().str.replace(' ','.')+\": \"+avatar.full_text+\" \").sum().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe6efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "avatar[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9567a49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_used2 = defaultdict(int)\n",
    "next_word2 = defaultdict(lambda: defaultdict(int))\n",
    "for i,word in enumerate(words[:-2]):\n",
    "    word_used2[word+' '+words[i+1]] += 1\n",
    "    next_word2[word+' '+words[i+1]][words[i+2]] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fe06a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_word2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8061095",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_word_1 = \"\\nKatara:\".upper()\n",
    "current_word_2 = \"Water.\"\n",
    "print(current_word_1, end=' ')\n",
    "print(current_word_2, end=' ')\n",
    "for i in range(100):\n",
    "    probability_of_next_word = np.array(list(next_word2[current_word_1+' '+current_word_2].values()))/word_used2[current_word_1+' '+current_word_2]\n",
    "    randomly_chosen_next_word = stats.multinomial(p=probability_of_next_word, n=1).rvs(size=1)[0,:]\n",
    "    current_word_1,current_word_2 = current_word_2,np.array(list(next_word2[current_word_1+' '+current_word_2].keys()))[1==randomly_chosen_next_word][0]\n",
    "    print(current_word_2.replace('_', '').replace('-', ''), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19f61be",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_used3 = defaultdict(int)\n",
    "next_word3 = defaultdict(lambda: defaultdict(int))\n",
    "for i,word in enumerate(words[:-3]):\n",
    "    word_used3[word+' '+words[i+1]+' '+words[i+2]] += 1\n",
    "    next_word3[word+' '+words[i+1]+' '+words[i+2]][words[i+3]] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cec03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_word_1 = \"\\nKatara:\".upper()\n",
    "current_word_2 = \"Water.\"\n",
    "current_word_3 = \"Earth.\"\n",
    "print(current_word_1, end=' ')\n",
    "print(current_word_2, end=' ')\n",
    "print(current_word_3, end=' ')\n",
    "for i in range(100):\n",
    "    probability_of_next_word = np.array(list(next_word3[current_word_1+' '+current_word_2+' '+current_word_3].values()))/word_used3[current_word_1+' '+current_word_2+' '+current_word_3]\n",
    "    randomly_chosen_next_word = stats.multinomial(p=probability_of_next_word, n=1).rvs(size=1)[0,:]\n",
    "    current_word_1,current_word_2,current_word_3 = current_word_2,current_word_3,np.array(list(next_word3[current_word_1+' '+current_word_2+' '+current_word_3].keys()))[1==randomly_chosen_next_word][0]\n",
    "    print(current_word_3.replace('_', '').replace('-', ''), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb19fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "characters = Counter(\"\\n\"+avatar.character.str.upper().str.replace(' ','.')+\":\")\n",
    "\n",
    "nested_dict = lambda: defaultdict(nested_dict)\n",
    "word_used2C = nested_dict()\n",
    "next_word2C = nested_dict()\n",
    "\n",
    "for i,word in enumerate(words[:-2]):\n",
    "    \n",
    "    if word in characters:\n",
    "        character = word\n",
    "        \n",
    "    if character not in word_used2C:\n",
    "        word_used2C[character] = dict()\n",
    "    if word+' '+words[i+1] not in word_used2C[character]:\n",
    "        word_used2C[character][word+' '+words[i+1]] = 0\n",
    "    word_used2C[character][word+' '+words[i+1]] += 1\n",
    "\n",
    "    if character not in next_word2C:\n",
    "        next_word2C[character] = dict()\n",
    "    if word+' '+words[i+1] not in next_word2C[character]:\n",
    "        next_word2C[character][word+' '+words[i+1]] = dict()\n",
    "    if words[i+2] not in next_word2C[character][word+' '+words[i+1]]:\n",
    "        next_word2C[character][word+' '+words[i+1]][words[i+2]] = 0\n",
    "    next_word2C[character][word+' '+words[i+1]][words[i+2]] += 1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d6834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_word_1 = \"\\nKatara:\".upper()\n",
    "current_word_2 = \"Water.\"\n",
    "print(current_word_1, end=' ')\n",
    "print(current_word_2, end=' ')\n",
    "for i in range(100):\n",
    "    if current_word_1 in characters:\n",
    "        character = current_word_1\n",
    "\n",
    "    probability_of_next_word = np.array(list(next_word2C[character][current_word_1+' '+current_word_2].values()))/word_used2C[character][current_word_1+' '+current_word_2]\n",
    "    randomly_chosen_next_word = stats.multinomial(p=probability_of_next_word, n=1).rvs(size=1)[0,:]\n",
    "    current_word_1,current_word_2 = current_word_2,np.array(list(next_word2C[character][current_word_1+' '+current_word_2].keys()))[1==randomly_chosen_next_word][0]\n",
    "    print(current_word_2.replace('_', '').replace('-', ''), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481657b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f01818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
